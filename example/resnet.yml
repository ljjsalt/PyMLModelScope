name: TorchVision_AlexNet
framework:
    name: PyTorch
    version: 1.8.1
version: 1.0
description: >
    This model is a replication of the model described in the AlexNet publication.
    All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].
references:
    - https://arxiv.org/abs/1404.5997
    - https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py
    - https://pytorch.org/docs/stable/torchvision/index.html
license: BSD 3-Clause License
modality: general
inputs:
    - type: image
      description: the input image
      parameters:
          element_type: float32
          input_layer: 0
          layout: CHW
          color_mode: RGB
          dimensions: [3, 224, 224]
          mean: [123.675, 116.280, 103.530]
          scale: [58.395, 57.120, 57.375]  
outputs:
    - type: classification
      description: the probability
      parameters:
        element_type: float32
model:
    is_archive:
        false
    graph_path: https://s3.amazonaws.com/store.carml.org/models/pytorch/alexnet.pt
    graph_checksum: 50a8a0f7cb9c3caa8f50a89b59a820a9
    features_path: http://s3.amazonaws.com/store.carml.org/synsets/imagenet/synset.txt
    features_checksum: 4d234b5833aca44928065a180db3016a
preprocess: |
  from torchvision import transforms
  from PIL import Image
  preprocessor = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
  ])
  def preprocess(ctx, data):
    img = Image.open(dataset[int(data)]).convert('RGB')
    return preprocessor(img).numpy()
postprocess: |
  import json
  import numpy as np
  def postprocess(ctx, data):
    return [json.dumps([x.item()]) for x in np.argmax(data[0], axis = 1)]
attributes:
    kind: CNN
    training_dataset: ImageNet
    manifest_author: Yen-Hsiang Chang